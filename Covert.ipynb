{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting lxml>=3.1.0 (from python-docx)\n",
      "  Downloading lxml-5.1.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.5 kB)\n",
      "Collecting typing-extensions (from python-docx)\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lxml-5.1.1-cp312-cp312-macosx_10_9_universal2.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: typing-extensions, lxml, python-docx\n",
      "Successfully installed lxml-5.1.1 python-docx-1.1.0 typing-extensions-4.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: 'extracted_questions.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m         qa_pairs\u001b[38;5;241m.\u001b[39mappend([question, answer])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Write to a CSV file\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mextracted_questions.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     30\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(file)\n\u001b[1;32m     31\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: 'extracted_questions.csv'"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import csv\n",
    "\n",
    "# Load the Word document\n",
    "doc = Document('/Users/vrunal/Documents/ChatGPT Project/Data/Combined.docx')\n",
    "\n",
    "# This will hold all the extracted Q&A pairs\n",
    "qa_pairs = []\n",
    "\n",
    "# Iterate through each paragraph to find questions and potential answers\n",
    "for i, para in enumerate(doc.paragraphs):\n",
    "    text = para.text.strip()\n",
    "    \n",
    "    # Check if the paragraph ends with a question mark\n",
    "    if text.endswith(\"?\"):\n",
    "        question = text\n",
    "        answer = \"null\"  # Default answer\n",
    "        \n",
    "        # Try to get the next paragraph as the answer if it exists and doesn't end with \"?\"\n",
    "        if i + 1 < len(doc.paragraphs):\n",
    "            next_text = doc.paragraphs[i + 1].text.strip()\n",
    "            if not next_text.endswith(\"?\"):\n",
    "                answer = next_text\n",
    "        \n",
    "        # Append the Q&A pair to the list\n",
    "        qa_pairs.append([question, answer])\n",
    "\n",
    "# Write to a CSV file\n",
    "with open('extracted_questions.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Question\", \"Answer\"])\n",
    "    for qa_pair in qa_pairs:\n",
    "        writer.writerow(qa_pair)\n",
    "\n",
    "print(\"Questions extraction and CSV creation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions extraction and CSV creation complete.\n",
      "CSV file has been saved to: /Users/vrunal/Documents/ChatGPT Project/Data/extracted_questions.csv\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import csv\n",
    "\n",
    "# Load the Word document\n",
    "doc = Document('/Users/vrunal/Documents/ChatGPT Project/Data/Combined.docx')  # Update this path to the actual location of your document\n",
    "\n",
    "# This will hold all the extracted Q&A pairs\n",
    "qa_pairs = []\n",
    "\n",
    "# Iterate through each paragraph to find questions and potential answers\n",
    "for i, para in enumerate(doc.paragraphs):\n",
    "    text = para.text.strip()\n",
    "    \n",
    "    # Check if the paragraph ends with a question mark\n",
    "    if text.endswith(\"?\"):\n",
    "        question = text\n",
    "        answer = \"null\"  # Default answer\n",
    "        \n",
    "        # Try to get the next paragraph as the answer if it exists and doesn't end with \"?\"\n",
    "        if i + 1 < len(doc.paragraphs):\n",
    "            next_text = doc.paragraphs[i + 1].text.strip()\n",
    "            if not next_text.endswith(\"?\"):\n",
    "                answer = next_text\n",
    "        \n",
    "        # Append the Q&A pair to the list\n",
    "        qa_pairs.append([question, answer])\n",
    "\n",
    "# Specify the output path for the CSV file\n",
    "output_csv_path = '/Users/vrunal/Documents/ChatGPT Project/Data/extracted_questions.csv'\n",
    "\n",
    "# Writing the Q&A pairs to a CSV file\n",
    "with open(output_csv_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Question\", \"Answer\"])\n",
    "    for qa_pair in qa_pairs:\n",
    "        writer.writerow(qa_pair)\n",
    "\n",
    "print(\"Questions extraction and CSV creation complete.\")\n",
    "print(f\"CSV file has been saved to: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV file has been saved to: /Users/vrunal/Documents/ChatGPT Project/Data/cleaned_questions.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Paths for the input and output CSV files\n",
    "input_csv_path = '/Users/vrunal/Documents/ChatGPT Project/Data/extracted_questions.csv'  # Adjust this path to where your original CSV file is located\n",
    "cleaned_csv_path = '/Users/vrunal/Documents/ChatGPT Project/Data/cleaned_questions.csv'  # The path for the cleaned CSV file\n",
    "\n",
    "def clean_csv(input_csv, output_csv):\n",
    "    cleaned_qa_pairs = []\n",
    "\n",
    "    with open(input_csv, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            question, answer = row\n",
    "            # If the answer ends with \"?\" and is not 'null', treat it as a new question\n",
    "            if answer != 'null' and answer.strip().endswith(\"?\"):\n",
    "                cleaned_qa_pairs.append([question, 'null'])  # Add the original question with 'null' answer\n",
    "                cleaned_qa_pairs.append([answer, 'null'])  # Add the answer as a new question with 'null' answer\n",
    "            else:\n",
    "                cleaned_qa_pairs.append([question, answer])\n",
    "\n",
    "    # Write the cleaned Q&A pairs to a new CSV file\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Question\", \"Answer\"])  # Write the header\n",
    "        for qa_pair in cleaned_qa_pairs:\n",
    "            writer.writerow(qa_pair)\n",
    "\n",
    "    print(f\"Cleaned CSV file has been saved to: {output_csv}\")\n",
    "\n",
    "# Call the clean_csv function with the paths\n",
    "clean_csv(input_csv_path, cleaned_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
